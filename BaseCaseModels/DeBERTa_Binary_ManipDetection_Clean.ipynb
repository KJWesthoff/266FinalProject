{"cells":[{"cell_type":"markdown","id":"dbc10067","metadata":{"id":"dbc10067"},"source":["# RoBERTa-based Manipulation Detection (Binary Classification)\n","This notebook uses `roberta-base` to classify dialogue as manipulative or not using the MentalManip dataset."]},{"cell_type":"code","execution_count":33,"id":"6461a70b","metadata":{"executionInfo":{"elapsed":27064,"status":"ok","timestamp":1753120071669,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"6461a70b"},"outputs":[],"source":["!pip install -q transformers\n","!pip install -q datasets\n","!pip install -q evaluate\n","## transformers upgrade\n","!pip install -q --upgrade transformers\n","\n","## Datasets need upgrading to work\n","!pip install -q --upgrade datasets\n"]},{"cell_type":"code","execution_count":34,"id":"1caed700","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1753120071674,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"1caed700"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from sklearn.metrics import classification_report\n"]},{"cell_type":"code","execution_count":35,"id":"a25eddbe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2195,"status":"ok","timestamp":1753120073872,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"a25eddbe","outputId":"1f603b57-5698-4a0e-bfe8-16c3a28f84ed"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some datasets params were ignored: ['license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n","WARNING:datasets.load:Some datasets params were ignored: ['license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n"]},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'manipulative', 'technique', 'vulnerability'],\n","        num_rows: 4000\n","    })\n","})\n"]}],"source":["# Load the MentalManip dataset (binary classification)\n","# Load dataset\n","dataset = load_dataset(\"audreyeleven/MentalManip\", name=\"mentalmanip_maj\")\n","\n","print(dataset)\n"]},{"cell_type":"code","execution_count":36,"id":"dfe9a948","metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1753120073908,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"dfe9a948"},"outputs":[],"source":["# Ensure the 'manipulative' column is class-labeled\n","dataset = dataset.class_encode_column(\"manipulative\")\n","\n","\n"]},{"cell_type":"code","execution_count":37,"id":"9220dd58","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208,"referenced_widgets":["76833e6ec8284a529285e6115f3c08f3","46fc03b78f564adcbe42d0d6258f6f13","7a25d98b7e9849d4b68c63e577505056","08706f5766b243e49871b7c36f6e7421","f13bdf5331de499bb083e1b7bebe2934","4954d01058654db3b5a612df180d70d4","df4532e5ecce4c68b13f4287ae40388d","e75bf99895de4ee0857ab337c491222a","e39035f25a284d419c2232872cd508d1","23cf82d09ab5423fb2d0e8e425ffcf79","da0d114ab8e844719460bf4dfa511004"]},"executionInfo":{"elapsed":9738,"status":"ok","timestamp":1753120083654,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"9220dd58","outputId":"761fd8e7-db0e-4f3b-ac90-11c0ecb33a9f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76833e6ec8284a529285e6115f3c08f3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'manipulative', 'technique', 'vulnerability', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 4000\n","    })\n","})\n"]}],"source":["model_ckpt = \"microsoft/deberta-v3-small\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","\n","def tokenize_fn(example):\n","    return tokenizer(example[\"dialogue\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","tokenized = dataset.map(tokenize_fn, batched=True)\n","print(tokenized)"]},{"cell_type":"code","execution_count":38,"id":"BKbb0_-pJUu6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1753120083706,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"BKbb0_-pJUu6","outputId":"cc36318f-67ab-48d7-a19d-e06a3f0b03d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'labels', 'technique', 'vulnerability', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 3200\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'labels', 'technique', 'vulnerability', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 800\n","    })\n","})\n"]}],"source":["# Split the dataset into training and testing sets\n","train_test_split = tokenized[\"train\"].train_test_split(test_size=0.2) # Adjust the test_size as needed\n","\n","# Update the tokenized dataset with the new splits\n","tokenized[\"train\"] = train_test_split[\"train\"]\n","tokenized[\"test\"] = train_test_split[\"test\"]\n","\n","# Make the data work with the nomenclature\n","tokenized = tokenized.rename_column(\"manipulative\", \"labels\")\n","\n","print(tokenized)"]},{"cell_type":"code","execution_count":39,"id":"b952f4a8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1404,"status":"ok","timestamp":1753120085124,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"b952f4a8","outputId":"0bbddad0-e219-4e75-ee38-451fcb3a8233"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    model_ckpt,\n","    num_labels=2  # Binary classification\n",")\n"]},{"cell_type":"code","execution_count":40,"id":"60b1378d","metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1753120085170,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"60b1378d"},"outputs":[],"source":["## Training args\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./bert-binary-manip\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=4,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    load_best_model_at_end=True,\n","    run_name=\"bert-binary-manip\",\n","    report_to=\"none\",\n",")"]},{"cell_type":"code","execution_count":41,"id":"r_SG36p2hDTS","metadata":{"executionInfo":{"elapsed":5133,"status":"ok","timestamp":1753120090307,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"r_SG36p2hDTS"},"outputs":[],"source":["## Evaluation metrics\n","\n","import evaluate\n","import numpy as np\n","\n","accuracy = evaluate.load('accuracy')\n","precision = evaluate.load('precision')\n","recall = evaluate.load('recall')\n","f1 = evaluate.load('f1')\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions_argmax = np.argmax(predictions, axis=1)\n","\n","    return {\n","        \"accuracy\": accuracy.compute(predictions=predictions_argmax, references=labels)[\"accuracy\"],\n","        \"precision\": precision.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"precision\"],\n","        \"recall\": recall.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"recall\"],\n","        \"f1\": f1.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"f1\"],\n","    }"]},{"cell_type":"code","execution_count":42,"id":"3be5b395","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"elapsed":406166,"status":"ok","timestamp":1753120496478,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"3be5b395","outputId":"ec0dd947-d87e-4359-f147-ffcabff7e1e7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-42-499019960.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1600/1600 06:44, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.557600</td>\n","      <td>0.596833</td>\n","      <td>0.710000</td>\n","      <td>0.504100</td>\n","      <td>0.710000</td>\n","      <td>0.589591</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.630000</td>\n","      <td>0.585740</td>\n","      <td>0.725000</td>\n","      <td>0.694427</td>\n","      <td>0.725000</td>\n","      <td>0.687471</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.466600</td>\n","      <td>0.689020</td>\n","      <td>0.703750</td>\n","      <td>0.678127</td>\n","      <td>0.703750</td>\n","      <td>0.684365</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.267600</td>\n","      <td>0.923354</td>\n","      <td>0.698750</td>\n","      <td>0.672224</td>\n","      <td>0.698750</td>\n","      <td>0.679038</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1600, training_loss=0.48983207903802395, metrics={'train_runtime': 405.119, 'train_samples_per_second': 31.596, 'train_steps_per_second': 3.949, 'total_flos': 423910775193600.0, 'train_loss': 0.48983207903802395, 'epoch': 4.0})"]},"metadata":{},"execution_count":42}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","trainer.train()\n","\n"]},{"cell_type":"code","execution_count":43,"id":"nmjOPnkmM-Yk","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1753120496479,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"nmjOPnkmM-Yk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecce1c78-3ecc-4c60-d603-9fdc485c0587"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Loss: 0.26760\n","Validation Loss: 0.92335\n","Overfitting Ratio: 0.28981\n","Overfitting detected!\n"]}],"source":["\n","##  Easy eval results...\n","##  Get the log history from the trainer state\n","log_history = trainer.state.log_history\n","\n","# Initialize placeholders\n","last_train_loss = None\n","last_eval_loss = None\n","\n","# Iterate through log history to find the last recorded train and eval loss\n","for log in reversed(log_history):\n","    if last_eval_loss is None and \"eval_loss\" in log:\n","        last_eval_loss = log[\"eval_loss\"]\n","    if last_train_loss is None and \"loss\" in log:\n","        last_train_loss = log[\"loss\"]\n","    if last_train_loss is not None and last_eval_loss is not None:\n","        break\n","\n","# Calculate overfitting ratio\n","if last_train_loss is not None and last_eval_loss is not None:\n","    ratio = last_train_loss / last_eval_loss\n","    print(f\"Training Loss: {last_train_loss:.5f}\")\n","    print(f\"Validation Loss: {last_eval_loss:.5f}\")\n","    print(f\"Overfitting Ratio: {ratio:.5f}\")\n","    if ratio < 0.6:\n","        print(\"Overfitting detected!\")\n","    else:\n","        print(\"No significant overfitting.\")\n","else:\n","    print(\"Could not find both training and evaluation loss in log history.\")\n"]},{"cell_type":"code","execution_count":44,"id":"98a675a9","metadata":{"executionInfo":{"elapsed":3998,"status":"ok","timestamp":1753120500473,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"98a675a9","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"b4b02442-a815-4574-e75a-45633272e4e6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["                  precision    recall  f1-score   support\n","\n","non-manipulative       0.56      0.25      0.35       232\n","    manipulative       0.75      0.92      0.83       568\n","\n","        accuracy                           0.72       800\n","       macro avg       0.65      0.59      0.59       800\n","    weighted avg       0.69      0.72      0.69       800\n","\n"]}],"source":["# Predict on test set\n","preds = trainer.predict(tokenized[\"test\"])\n","y_pred = preds.predictions.argmax(-1)\n","y_true = preds.label_ids\n","\n","# Detailed classification report\n","print(classification_report(y_true, y_pred, target_names=[\"non-manipulative\", \"manipulative\"]))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"76833e6ec8284a529285e6115f3c08f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46fc03b78f564adcbe42d0d6258f6f13","IPY_MODEL_7a25d98b7e9849d4b68c63e577505056","IPY_MODEL_08706f5766b243e49871b7c36f6e7421"],"layout":"IPY_MODEL_f13bdf5331de499bb083e1b7bebe2934"}},"46fc03b78f564adcbe42d0d6258f6f13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4954d01058654db3b5a612df180d70d4","placeholder":"​","style":"IPY_MODEL_df4532e5ecce4c68b13f4287ae40388d","value":"Map: 100%"}},"7a25d98b7e9849d4b68c63e577505056":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e75bf99895de4ee0857ab337c491222a","max":4000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e39035f25a284d419c2232872cd508d1","value":4000}},"08706f5766b243e49871b7c36f6e7421":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23cf82d09ab5423fb2d0e8e425ffcf79","placeholder":"​","style":"IPY_MODEL_da0d114ab8e844719460bf4dfa511004","value":" 4000/4000 [00:05&lt;00:00, 781.77 examples/s]"}},"f13bdf5331de499bb083e1b7bebe2934":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4954d01058654db3b5a612df180d70d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df4532e5ecce4c68b13f4287ae40388d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e75bf99895de4ee0857ab337c491222a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e39035f25a284d419c2232872cd508d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23cf82d09ab5423fb2d0e8e425ffcf79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da0d114ab8e844719460bf4dfa511004":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}