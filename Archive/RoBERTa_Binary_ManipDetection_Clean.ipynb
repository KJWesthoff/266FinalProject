{"cells":[{"cell_type":"markdown","id":"dbc10067","metadata":{"id":"dbc10067"},"source":["# RoBERTa-based Manipulation Detection (Binary Classification)\n","This notebook uses `roberta-base` to classify dialogue as manipulative or not using the MentalManip dataset."]},{"cell_type":"code","execution_count":1,"id":"6461a70b","metadata":{"executionInfo":{"elapsed":59005,"status":"ok","timestamp":1752441476905,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"6461a70b"},"outputs":[],"source":["!pip install -q transformers\n","!pip install -q datasets\n","!pip install -q evaluate\n","## transformers upgrade\n","!pip install -q --upgrade transformers\n","\n","## Datasets need upgrading to work\n","!pip install -q --upgrade datasets\n"]},{"cell_type":"code","execution_count":2,"id":"1caed700","metadata":{"executionInfo":{"elapsed":22241,"status":"ok","timestamp":1752441499155,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"1caed700"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from sklearn.metrics import classification_report\n"]},{"cell_type":"code","execution_count":13,"id":"a25eddbe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1185,"status":"ok","timestamp":1752442491179,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"a25eddbe","outputId":"3fac6d06-4a4a-45e2-e695-1fd0ae1c7167"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some datasets params were ignored: ['license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n","WARNING:datasets.load:Some datasets params were ignored: ['license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n"]},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'manipulative', 'technique', 'vulnerability'],\n","        num_rows: 4000\n","    })\n","})\n"]}],"source":["# Load the MentalManip dataset (binary classification)\n","# Load dataset\n","dataset = load_dataset(\"audreyeleven/MentalManip\", name=\"mentalmanip_maj\")\n","\n","print(dataset)\n"]},{"cell_type":"code","execution_count":14,"id":"dfe9a948","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1752442493518,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"dfe9a948"},"outputs":[],"source":["# Ensure the 'manipulative' column is class-labeled\n","dataset = dataset.class_encode_column(\"manipulative\")\n","\n","\n"]},{"cell_type":"code","execution_count":15,"id":"9220dd58","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["096715fac88e465ead51a775d7e25d87","5ad1f40d61af41bdbbf177ae69fb2b95","8bffc71b913a47878141ed33b73b2d42","320e2c9dfdad411e8be3b93603c9f831","57095eab969d427e954c495e02cde1b6","29ca615637ca4e62a4bb34d844cddfab","611894a9f5014d1dbc1e650539688f3f","ed6f261a8c1f4de18f3e42b8c5bfcc07","9f646949806f47069fafac8b68b2c2c9","d94743bbaa87402dbd3bbd4f898dde07","e25244d42d9c444696721fb9bb478a63"]},"executionInfo":{"elapsed":1862,"status":"ok","timestamp":1752442496667,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"9220dd58","outputId":"28e2c20e-7e38-4276-8ad6-43f547438a5c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"096715fac88e465ead51a775d7e25d87"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'manipulative', 'technique', 'vulnerability', 'input_ids', 'attention_mask'],\n","        num_rows: 4000\n","    })\n","})\n"]}],"source":["model_ckpt = \"roberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","\n","def tokenize_fn(example):\n","    return tokenizer(example[\"dialogue\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","tokenized = dataset.map(tokenize_fn, batched=True)\n","print(tokenized)"]},{"cell_type":"code","execution_count":16,"id":"BKbb0_-pJUu6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1752442499244,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"BKbb0_-pJUu6","outputId":"9c5836a0-ae6c-441a-eaa1-fc6556bb75bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'labels', 'technique', 'vulnerability', 'input_ids', 'attention_mask'],\n","        num_rows: 3200\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'labels', 'technique', 'vulnerability', 'input_ids', 'attention_mask'],\n","        num_rows: 800\n","    })\n","})\n"]}],"source":["# Split the dataset into training and testing sets\n","train_test_split = tokenized[\"train\"].train_test_split(test_size=0.2) # Adjust the test_size as needed\n","\n","# Update the tokenized dataset with the new splits\n","tokenized[\"train\"] = train_test_split[\"train\"]\n","tokenized[\"test\"] = train_test_split[\"test\"]\n","\n","# Make the data work with the nomenclature\n","tokenized = tokenized.rename_column(\"manipulative\", \"labels\")\n","\n","print(tokenized)"]},{"cell_type":"code","execution_count":17,"id":"b952f4a8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":184,"status":"ok","timestamp":1752442501246,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"b952f4a8","outputId":"707249fb-e65c-47af-97af-fe594b974904"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    model_ckpt,\n","    num_labels=2  # Binary classification\n",")\n"]},{"cell_type":"code","execution_count":18,"id":"60b1378d","metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1752442502898,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"60b1378d"},"outputs":[],"source":["## Training args\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./bert-binary-manip\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=4,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    load_best_model_at_end=True,\n","    run_name=\"bert-binary-manip\",\n","    report_to=\"none\",\n",")\n"]},{"cell_type":"code","execution_count":19,"id":"r_SG36p2hDTS","metadata":{"executionInfo":{"elapsed":1909,"status":"ok","timestamp":1752442507793,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"r_SG36p2hDTS"},"outputs":[],"source":["## Evaluation metrics\n","\n","import evaluate\n","import numpy as np\n","\n","accuracy = evaluate.load('accuracy')\n","precision = evaluate.load('precision')\n","recall = evaluate.load('recall')\n","f1 = evaluate.load('f1')\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions_argmax = np.argmax(predictions, axis=1)\n","\n","    return {\n","        \"accuracy\": accuracy.compute(predictions=predictions_argmax, references=labels)[\"accuracy\"],\n","        \"precision\": precision.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"precision\"],\n","        \"recall\": recall.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"recall\"],\n","        \"f1\": f1.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"f1\"],\n","    }"]},{"cell_type":"code","execution_count":20,"id":"3be5b395","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"elapsed":428701,"status":"ok","timestamp":1752442941403,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"3be5b395","outputId":"1b712444-feb1-4a7a-82c7-1b5d35f92d73"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-20-499019960.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [800/800 07:07, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.614000</td>\n","      <td>0.578383</td>\n","      <td>0.710000</td>\n","      <td>0.504100</td>\n","      <td>0.710000</td>\n","      <td>0.589591</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.577300</td>\n","      <td>0.566077</td>\n","      <td>0.733750</td>\n","      <td>0.711089</td>\n","      <td>0.733750</td>\n","      <td>0.680695</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.452900</td>\n","      <td>0.580028</td>\n","      <td>0.728750</td>\n","      <td>0.700444</td>\n","      <td>0.728750</td>\n","      <td>0.693961</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.350000</td>\n","      <td>0.670154</td>\n","      <td>0.726250</td>\n","      <td>0.699255</td>\n","      <td>0.726250</td>\n","      <td>0.698576</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=800, training_loss=0.5272493395209312, metrics={'train_runtime': 427.9642, 'train_samples_per_second': 29.909, 'train_steps_per_second': 1.869, 'total_flos': 841955377152000.0, 'train_loss': 0.5272493395209312, 'epoch': 4.0})"]},"metadata":{},"execution_count":20}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","trainer.train()\n","\n"]},{"cell_type":"code","execution_count":21,"id":"nmjOPnkmM-Yk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1752442941406,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"nmjOPnkmM-Yk","outputId":"308d8a35-0112-45bb-92b7-1147f68139d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Loss: 0.35000\n","Validation Loss: 0.67015\n","Overfitting Ratio: 0.52227\n","Overfitting detected!\n"]}],"source":["\n","##  Easy eval results...\n","##  Get the log history from the trainer state\n","log_history = trainer.state.log_history\n","\n","# Initialize placeholders\n","last_train_loss = None\n","last_eval_loss = None\n","\n","# Iterate through log history to find the last recorded train and eval loss\n","for log in reversed(log_history):\n","    if last_eval_loss is None and \"eval_loss\" in log:\n","        last_eval_loss = log[\"eval_loss\"]\n","    if last_train_loss is None and \"loss\" in log:\n","        last_train_loss = log[\"loss\"]\n","    if last_train_loss is not None and last_eval_loss is not None:\n","        break\n","\n","# Calculate overfitting ratio\n","if last_train_loss is not None and last_eval_loss is not None:\n","    ratio = last_train_loss / last_eval_loss\n","    print(f\"Training Loss: {last_train_loss:.5f}\")\n","    print(f\"Validation Loss: {last_eval_loss:.5f}\")\n","    print(f\"Overfitting Ratio: {ratio:.5f}\")\n","    if ratio < 0.6:\n","        print(\"Overfitting detected!\")\n","    else:\n","        print(\"No significant overfitting.\")\n","else:\n","    print(\"Could not find both training and evaluation loss in log history.\")\n"]},{"cell_type":"code","execution_count":22,"id":"98a675a9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":5534,"status":"ok","timestamp":1752442946929,"user":{"displayName":"Karl-Johan Westhoff","userId":"00382218864597560286"},"user_tz":420},"id":"98a675a9","outputId":"a1eedde2-d950-4b1f-b100-40b8a11f3066"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["                  precision    recall  f1-score   support\n","\n","non-manipulative       0.63      0.20      0.30       232\n","    manipulative       0.74      0.95      0.84       568\n","\n","        accuracy                           0.73       800\n","       macro avg       0.69      0.58      0.57       800\n","    weighted avg       0.71      0.73      0.68       800\n","\n"]}],"source":["# Predict on test set\n","preds = trainer.predict(tokenized[\"test\"])\n","y_pred = preds.predictions.argmax(-1)\n","y_true = preds.label_ids\n","\n","# Detailed classification report\n","print(classification_report(y_true, y_pred, target_names=[\"non-manipulative\", \"manipulative\"]))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"096715fac88e465ead51a775d7e25d87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ad1f40d61af41bdbbf177ae69fb2b95","IPY_MODEL_8bffc71b913a47878141ed33b73b2d42","IPY_MODEL_320e2c9dfdad411e8be3b93603c9f831"],"layout":"IPY_MODEL_57095eab969d427e954c495e02cde1b6"}},"5ad1f40d61af41bdbbf177ae69fb2b95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29ca615637ca4e62a4bb34d844cddfab","placeholder":"​","style":"IPY_MODEL_611894a9f5014d1dbc1e650539688f3f","value":"Map: 100%"}},"8bffc71b913a47878141ed33b73b2d42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed6f261a8c1f4de18f3e42b8c5bfcc07","max":4000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f646949806f47069fafac8b68b2c2c9","value":4000}},"320e2c9dfdad411e8be3b93603c9f831":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d94743bbaa87402dbd3bbd4f898dde07","placeholder":"​","style":"IPY_MODEL_e25244d42d9c444696721fb9bb478a63","value":" 4000/4000 [00:01&lt;00:00, 2830.67 examples/s]"}},"57095eab969d427e954c495e02cde1b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29ca615637ca4e62a4bb34d844cddfab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"611894a9f5014d1dbc1e650539688f3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed6f261a8c1f4de18f3e42b8c5bfcc07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f646949806f47069fafac8b68b2c2c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d94743bbaa87402dbd3bbd4f898dde07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e25244d42d9c444696721fb9bb478a63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}