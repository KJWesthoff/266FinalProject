{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc10067",
   "metadata": {
    "id": "dbc10067"
   },
   "source": [
    "# RoBERTa-based Manipulation Detection (Binary Classification) ith PEFT/LORA added\n",
    "This notebook uses `roberta-base` to classify dialogue as manipulative or not using the MentalManip dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6461a70b",
   "metadata": {
    "executionInfo": {
     "elapsed": 45742,
     "status": "ok",
     "timestamp": 1752450062591,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "6461a70b"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate\n",
    "## transformers upgrade\n",
    "!pip install -q --upgrade transformers\n",
    "\n",
    "## Datasets need upgrading to work\n",
    "!pip install -q --upgrade datasets\n",
    "\n",
    "## LoRA addon\n",
    "!pip install -q peft accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1caed700",
   "metadata": {
    "executionInfo": {
     "elapsed": 27535,
     "status": "ok",
     "timestamp": 1752450090132,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "1caed700"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "kfQpJJa9_E6p",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752451094439,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "kfQpJJa9_E6p"
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25eddbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1163,
     "status": "ok",
     "timestamp": 1752451095604,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "a25eddbe",
    "outputId": "06ca0334-a2b0-410b-e1a6-d34bed771c87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some datasets params were ignored: ['license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n",
      "WARNING:datasets.load:Some datasets params were ignored: ['license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'manipulative', 'technique', 'vulnerability'],\n",
      "        num_rows: 4000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the MentalManip dataset (binary classification)\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"audreyeleven/MentalManip\", name=\"mentalmanip_maj\")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe9a948",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752451095610,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "dfe9a948"
   },
   "outputs": [],
   "source": [
    "# Ensure the 'manipulative' column is class-labeled\n",
    "dataset = dataset.class_encode_column(\"manipulative\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "DClawgyd16x0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "356d852fd827494088360cc98c093605",
      "fdd828c4f81c4c47a3a5d388466af736",
      "9fb13e0f881a453da09515449a8fbef2",
      "063914779cc34f42bbc1e2b81ae0398c",
      "be8584e085144cea9269883aef1a88e8",
      "5c9dcfda5c694be4b3841cfe704b98f2",
      "078c181d89a747f193128c84a2c2c974",
      "ed0e8495b4b64665a65e59976cb53cf9",
      "97618c4ec9d049299dc70d24091d900c",
      "72e18456872540ffb48f5133c40151cb",
      "63f3002db1124310b99f3c324fdd3762"
     ]
    },
    "executionInfo": {
     "elapsed": 2345,
     "status": "ok",
     "timestamp": 1752451097960,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "DClawgyd16x0",
    "outputId": "052a42ad-faec-4d6c-b493-a7963fe329f9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356d852fd827494088360cc98c093605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'manipulative', 'technique', 'vulnerability', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"dialogue\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized = dataset.map(tokenize_fn, batched=True)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Uenf6WH_1W2D",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752451097974,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "Uenf6WH_1W2D"
   },
   "outputs": [],
   "source": [
    "## Setup the PEFT addon\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Define your LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,           # Sequence classification\n",
    "    inference_mode=False,                 # True = inference only\n",
    "    r=8,                                  # Low-rank dimension\n",
    "    lora_alpha=16,                        # Scaling factor\n",
    "    lora_dropout=0.1,                     # Dropout in LoRA layers\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"]     # Apply only to LoRA layers\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9220dd58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1752451098161,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "9220dd58",
    "outputId": "72bb6175-29b0-4c62-b7fe-a4a406ef4ce0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.roberta.encoder.layer.0.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.base_layer\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_A\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_B\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_magnitude_vector\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.key\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.base_layer\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_dropout\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_dropout.default\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_A\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_A.default\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_B\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_B.default\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_embedding_A\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_embedding_B\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_magnitude_vector\n",
      "trainable params: 887,042 || all params: 125,534,212 || trainable%: 0.7066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=2)\n",
    "\n",
    "# Wrap with LoRA\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "\n",
    "# Pring trainable layers\n",
    "for name, module in model.named_modules():\n",
    "    if \"attention\" in name and any(k in name for k in [\"query\", \"key\", \"value\"]):\n",
    "        print(name)\n",
    "\n",
    "\n",
    "# Optional: Show how many parameters are trainable\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "BKbb0_-pJUu6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1752451098214,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "BKbb0_-pJUu6",
    "outputId": "afc1c19a-c939-4b0d-a937-26dd180fbb0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'labels', 'technique', 'vulnerability', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'labels', 'technique', 'vulnerability', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_test_split = tokenized[\"train\"].train_test_split(test_size=0.2) # Adjust the test_size as needed\n",
    "\n",
    "# Update the tokenized dataset with the new splits\n",
    "tokenized[\"train\"] = train_test_split[\"train\"]\n",
    "tokenized[\"test\"] = train_test_split[\"test\"]\n",
    "\n",
    "# Make the data work with the nomenclature\n",
    "tokenized = tokenized.rename_column(\"manipulative\", \"labels\")\n",
    "\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b952f4a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1752451098403,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "b952f4a8",
    "outputId": "479db87a-bb16-48bb-9be9-d9a93096dded"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=2  # Binary classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b1378d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752451098407,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "60b1378d"
   },
   "outputs": [],
   "source": [
    "## Training args\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-binary-manip\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    run_name=\"bert-binary-manip\",\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "r_SG36p2hDTS",
   "metadata": {
    "executionInfo": {
     "elapsed": 1759,
     "status": "ok",
     "timestamp": 1752451100175,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "r_SG36p2hDTS"
   },
   "outputs": [],
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions_argmax = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions_argmax, references=labels)[\"accuracy\"],\n",
    "        \"precision\": precision.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"recall\"],\n",
    "        \"f1\": f1.compute(predictions=predictions_argmax, references=labels, average='weighted')[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3be5b395",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 1128387,
     "status": "ok",
     "timestamp": 1752452228568,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "3be5b395",
    "outputId": "978c2ee8-2fdd-4184-d32b-56d58e9d840a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-24-3748925629.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1600/1600 18:46, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.616400</td>\n",
       "      <td>0.589591</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.681268</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.658982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.601798</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.589591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.577618</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.694231</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.686543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.588800</td>\n",
       "      <td>0.603179</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.589591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.614099</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.673043</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.667220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.600194</td>\n",
       "      <td>0.686250</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.686250</td>\n",
       "      <td>0.682597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.728750</td>\n",
       "      <td>0.700155</td>\n",
       "      <td>0.728750</td>\n",
       "      <td>0.679233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>0.614563</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.676894</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.677832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1600, training_loss=0.5600223599374294, metrics={'train_runtime': 1126.9041, 'train_samples_per_second': 22.717, 'train_steps_per_second': 1.42, 'total_flos': 1683910754304000.0, 'train_loss': 0.5600223599374294, 'epoch': 8.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "nmjOPnkmM-Yk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1752452228582,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "nmjOPnkmM-Yk",
    "outputId": "9f04eb7f-02f4-40dc-a7eb-588764a5b845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.36940\n",
      "Validation Loss: 0.61456\n",
      "Overfitting Ratio: 0.60108\n",
      "No significant overfitting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##  Easy eval results...\n",
    "##  Get the log history from the trainer state\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# Initialize placeholders\n",
    "last_train_loss = None\n",
    "last_eval_loss = None\n",
    "\n",
    "# Iterate through log history to find the last recorded train and eval loss\n",
    "for log in reversed(log_history):\n",
    "    if last_eval_loss is None and \"eval_loss\" in log:\n",
    "        last_eval_loss = log[\"eval_loss\"]\n",
    "    if last_train_loss is None and \"loss\" in log:\n",
    "        last_train_loss = log[\"loss\"]\n",
    "    if last_train_loss is not None and last_eval_loss is not None:\n",
    "        break\n",
    "\n",
    "# Calculate overfitting ratio\n",
    "if last_train_loss is not None and last_eval_loss is not None:\n",
    "    ratio = last_train_loss / last_eval_loss\n",
    "    print(f\"Training Loss: {last_train_loss:.5f}\")\n",
    "    print(f\"Validation Loss: {last_eval_loss:.5f}\")\n",
    "    print(f\"Overfitting Ratio: {ratio:.5f}\")\n",
    "    if ratio < 0.6:\n",
    "        print(\"Overfitting detected!\")\n",
    "    else:\n",
    "        print(\"No significant overfitting.\")\n",
    "else:\n",
    "    print(\"Could not find both training and evaluation loss in log history.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a675a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 5938,
     "status": "ok",
     "timestamp": 1752452234522,
     "user": {
      "displayName": "Karl-Johan Westhoff",
      "userId": "00382218864597560286"
     },
     "user_tz": 420
    },
    "id": "98a675a9",
    "outputId": "fc9ca312-c5e9-4cd5-dfa8-73308ad5409b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-manipulative       0.56      0.25      0.35       232\n",
      "    manipulative       0.75      0.92      0.83       568\n",
      "\n",
      "        accuracy                           0.72       800\n",
      "       macro avg       0.65      0.58      0.59       800\n",
      "    weighted avg       0.69      0.72      0.69       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "preds = trainer.predict(tokenized[\"test\"])\n",
    "y_pred = preds.predictions.argmax(-1)\n",
    "y_true = preds.label_ids\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_true, y_pred, target_names=[\"non-manipulative\", \"manipulative\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee43eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset (assuming MentalManip is available locally or via HuggingFace)\n",
    "dataset = load_dataset(\"csv\", data_files={\n",
    "    \"train\": \"mentalmanip_train.csv\",\n",
    "    \"validation\": \"mentalmanip_val.csv\"\n",
    "})\n",
    "\n",
    "# Define class labels\n",
    "label_list = [\n",
    "    \"Denial\", \"Evasion\", \"Feigning Innocence\", \"Rationalization\",\n",
    "    \"Playing the Victim Role\", \"Playing the Servant Role\", \"Shaming or Belittlement\",\n",
    "    \"Intimidation\", \"Brandishing Anger\", \"Accusation\", \"Persuasion or Seduction\"\n",
    "]\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "num_labels = len(label_list)\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(example):\n",
    "    example[\"label\"] = label2id[example[\"technique\"]]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(encode_labels)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", num_labels=num_labels, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1N4udwbzS4mbqKTH2uOzDoUICE_72lxyo",
     "timestamp": 1752444376839
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "063914779cc34f42bbc1e2b81ae0398c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72e18456872540ffb48f5133c40151cb",
      "placeholder": "",
      "style": "IPY_MODEL_63f3002db1124310b99f3c324fdd3762",
      "value": "4000/4000[00:01&lt;00:00,2413.63examples/s]"
     }
    },
    "078c181d89a747f193128c84a2c2c974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "356d852fd827494088360cc98c093605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdd828c4f81c4c47a3a5d388466af736",
       "IPY_MODEL_9fb13e0f881a453da09515449a8fbef2",
       "IPY_MODEL_063914779cc34f42bbc1e2b81ae0398c"
      ],
      "layout": "IPY_MODEL_be8584e085144cea9269883aef1a88e8"
     }
    },
    "5c9dcfda5c694be4b3841cfe704b98f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63f3002db1124310b99f3c324fdd3762": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72e18456872540ffb48f5133c40151cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97618c4ec9d049299dc70d24091d900c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fb13e0f881a453da09515449a8fbef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed0e8495b4b64665a65e59976cb53cf9",
      "max": 4000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_97618c4ec9d049299dc70d24091d900c",
      "value": 4000
     }
    },
    "be8584e085144cea9269883aef1a88e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed0e8495b4b64665a65e59976cb53cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdd828c4f81c4c47a3a5d388466af736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c9dcfda5c694be4b3841cfe704b98f2",
      "placeholder": "",
      "style": "IPY_MODEL_078c181d89a747f193128c84a2c2c974",
      "value": "Map:100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
